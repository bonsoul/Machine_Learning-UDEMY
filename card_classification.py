# -*- coding: utf-8 -*-
"""Card classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10AQAltVeSb2I-44hlNEDp9tRZtohB05L

## Playing Card Image Classifier Using EfficientNet and PyTorch
"""

# core pytorch modules

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models, datasets
from torchvision.datasets import ImageFolder
import torchvision.transforms as T

# visualization and utilities

import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

#import timm

import kagglehub

# Download latest version
path = kagglehub.dataset_download("gpiosenka/cards-image-datasetclassification")

print("Path to dataset files:", path)

dataset  =path

import os
from PIL import Image
import matplotlib.pyplot as plt

train_dr = os.path.join(dataset, "train")

class_names = os.listdir(train_dr)
print("Classes:", class_names)

plt.figure(figsize=(12,8))

for i, class_name in enumerate(class_names[:6]):
  class_path = os.path.join(train_dr, class_name)
  image_files = os.listdir(class_path)
  image_path = os.path.join(class_path, image_files[0])
  image = Image.open(image_path)
  plt.subplot(2, 3, i + 1)
  plt.imshow(image)
  plt.title(class_name)
  plt.axis('off')
  plt.show()

classes = os.listdir(dataset)

print("Classes:", classes)

# Remove the line that redefines Dataset
# del Dataset
from torch.utils.data import Dataset

print("str =", str)
print("Dataset =", Dataset)
print("ImageFolder =", ImageFolder)

# custom dataset


class PlayingCardDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        # Store ImageFolder dataset internally
        self._data = ImageFolder(root=data_dir, transform=transform)

    def __len__(self):
        return len(self._data)

    def __getitem__(self, idx):
        # Return (image, label) pair
        image, label = self._data[idx]
        return image, label

!pip install timm torch torchvision pillow

import timm

from urllib.request import urlopen
from PIL import Image

img = Image.open(urlopen(
    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'
)).convert('RGB')

img

class SimpleCardClassifier(nn.Module):
    def __init__(self, num_classes=53):
        super().__init__()

        # Load EfficientNet-B0 backbone without classification head
        self.base_model = timm.create_model(
            'efficientnet_b0',
            pretrained=True,
            num_classes=0,   # removes final classifier automatically
            global_pool='avg'  # ensures we get a flattened feature vector
        )

        in_features = self.base_model.num_features  # typically 1280
        self.classifier = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(in_features, num_classes)
        )

    def forward(self, x):
        x = self.base_model(x)  # feature vector shape: [batch, 1280]
        x = self.classifier(x)  # output shape: [batch, num_classes]
        return x

model = SimpleCardClassifier(num_classes=53)
print(model(torch.randn(1, 3, 224, 224)).shape)

#define transformation pipeline for images

transform = transforms.Compose([transforms.Resize((128, 128)),
                                transforms.ToTensor()])

#dataset directories
# Subdirectories
train_dr = os.path.join(dataset, "train")
valid_dr = os.path.join(dataset, "valid")
test_dr  = os.path.join(dataset, "test")

#create training and validation
train_dataset = PlayingCardDataset(train_dr, transform=transform)
val_dataset = PlayingCardDataset(valid_dr, transform=transform)
test_dataset = PlayingCardDataset(test_dr, transform=transform)

#data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)


device  =torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

#initialize the model

model = SimpleCardClassifier(num_classes=53)
model.to(device)

#loss function
criterion = nn.CrossEntropyLoss()

#adam optimizer
optimizer = optim.Adam(model.parameters(), lr=0.001)

# set nmbers of epochs and track loss

num_epochs = 5

train_losses, val_losses = [], []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    #training loop
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * labels.size(0)

    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)


    #validation loop
    model.eval()
    running_loss = 0.0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * labels.size(0)
    val_loss = running_loss / len(val_loader.dataset)
    val_losses.append(val_loss)

    print(f'Epoch {epoch+1}/{num_epochs} - Train loss :{train_loss:.4f}, validation loss: {val_loss:.4f}')

#plot traing and validation


plt.plot(train_losses, label="Training Loss")
plt.plot(val_losses, label="Validation Loss")
plt.legend()
plt.title("Loss over Epochs")
plt.show()

#  Preprocess a single image
def preprocess_image(image_path, transform):
    """
    Load and preprocess a single image for model inference.

    Args:
        image_path (str): Path to the image file.
        transform (callable): Torchvision transform for preprocessing.

    Returns:
        tuple: (original_image (PIL.Image), preprocessed_tensor (1x3xHxW))
    """
    # Load and ensure RGB format
    image = Image.open(image_path).convert("RGB")

    # Apply preprocessing transforms and add batch dimension
    image_tensor = transform(image).unsqueeze(0)

    return image, image_tensor


#  Run model prediction
def predict(model, image_tensor, device):
    """
    Run inference on a preprocessed image tensor.

    Args:
        model (torch.nn.Module): Trained model for inference.
        image_tensor (torch.Tensor): Preprocessed image tensor (1x3xHxW).
        device (str or torch.device): 'cuda' or 'cpu'.

    Returns:
        np.ndarray: Probability distribution over classes.
    """
    model.eval()

    with torch.no_grad():
        image_tensor = image_tensor.to(device)
        outputs = model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)

    return probabilities.squeeze().cpu().numpy()  # shape: (num_classes,)


#  Visualize top-k predictions
def visualize_predictions(original_image, probabilities, class_names, top_k=5):
    """
    Display the original image and a bar chart of the top-k predicted classes.

    Args:
        original_image (PIL.Image): The original input image.
        probabilities (np.ndarray): Model output probabilities.
        class_names (list): List of all class labels.
        top_k (int): Number of top predictions to display.
    """
    # Identify top-k predictions
    top_indices = np.argsort(probabilities)[-top_k:][::-1]
    top_probs = probabilities[top_indices]
    top_labels = [class_names[i] for i in top_indices]

    # Plot results
    fig, axarr = plt.subplots(1, 2, figsize=(14, 6))

    # Left: Image
    axarr[0].imshow(original_image)
    axarr[0].axis("off")
    axarr[0].set_title("Input Image", fontsize=14)

    # Right: Top-k bar chart
    axarr[1].barh(top_labels[::-1], top_probs[::-1], color="skyblue")
    axarr[1].set_xlabel("Probability")
    axarr[1].set_title("Top Class Predictions")
    axarr[1].set_xlim(0, 1)

    plt.tight_layout()
    plt.show()

# Load and transform a test image
test_image_path = "/kaggle/input/cards-image-datasetclassification/test/five of diamonds/2.jpg"

transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# Preprocess image
original_image, image_tensor = preprocess_image(test_image_path, transform)

# Make predictions
probabilities = predict(model, image_tensor, device)

# Get class names from training dataset
class_names = train_dataset._data.classes

# Display predictions
visualize_predictions(original_image, probabilities, class_names)

# Load and transform a test image
test_image_path = "/kaggle/input/cards-image-datasetclassification/test/ace of spades/2.jpg"

transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# Preprocess image
original_image, image_tensor = preprocess_image(test_image_path, transform)

# Make predictions
probabilities = predict(model, image_tensor, device)

# Get class names from training dataset
class_names = train_dataset._data.classes

# Display predictions
visualize_predictions(original_image, probabilities, class_names)

